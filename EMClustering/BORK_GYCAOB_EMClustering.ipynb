{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, HalvingRandomSearchCV, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA, KernelPCA, FastICA\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from enum import Enum\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Params\n",
    "algo_name = 'EMClustering'\n",
    "\n",
    "# Read\n",
    "X_train = pd.read_csv('../pc_X_train.csv')\n",
    "y_train = pd.read_csv('../pc_y_train.csv')\n",
    "y_train = y_train.iloc[:, -1] # With iloc we extract the labels\n",
    "X_test = pd.read_csv('../pc_X_test.csv')\n",
    "ids = X_test.iloc[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Fitting the mixture model failed because some components have ill-defined empirical covariance (for instance caused by singleton or collapsed samples). Try to decrease the number of components, or increase reg_covar.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/mixture/_gaussian_mixture.py:329\u001b[0m, in \u001b[0;36m_compute_precision_cholesky\u001b[0;34m(covariances, covariance_type)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 329\u001b[0m     cov_chol \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39;49mcholesky(covariance, lower\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    330\u001b[0m \u001b[39mexcept\u001b[39;00m linalg\u001b[39m.\u001b[39mLinAlgError:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py:89\u001b[0m, in \u001b[0;36mcholesky\u001b[0;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39mCompute the Cholesky decomposition of a matrix.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m \n\u001b[1;32m     88\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m c, lower \u001b[39m=\u001b[39m _cholesky(a, lower\u001b[39m=\u001b[39;49mlower, overwrite_a\u001b[39m=\u001b[39;49moverwrite_a, clean\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     90\u001b[0m                      check_finite\u001b[39m=\u001b[39;49mcheck_finite)\n\u001b[1;32m     91\u001b[0m \u001b[39mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py:37\u001b[0m, in \u001b[0;36m_cholesky\u001b[0;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m info \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 37\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-th leading minor of the array is not positive \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mdefinite\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m info)\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m info \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mLinAlgError\u001b[0m: 264-th leading minor of the array is not positive definite",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/ibork/University/Data Mining and Machine Learning/AssignmentProject/FinalAssignment/EMClustering/BORK_GYCAOB_EMClustering.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ibork/University/Data%20Mining%20and%20Machine%20Learning/AssignmentProject/FinalAssignment/EMClustering/BORK_GYCAOB_EMClustering.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m GaussianMixture(n_components\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, reg_covar\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ibork/University/Data%20Mining%20and%20Machine%20Learning/AssignmentProject/FinalAssignment/EMClustering/BORK_GYCAOB_EMClustering.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_predict(X_train)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/mixture/_base.py:235\u001b[0m, in \u001b[0;36mBaseMixture.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_print_verbose_msg_init_beg(init)\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m do_init:\n\u001b[0;32m--> 235\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize_parameters(X, random_state)\n\u001b[1;32m    237\u001b[0m lower_bound \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf \u001b[39mif\u001b[39;00m do_init \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlower_bound_\n\u001b[1;32m    239\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/mixture/_base.py:140\u001b[0m, in \u001b[0;36mBaseMixture._initialize_parameters\u001b[0;34m(self, X, random_state)\u001b[0m\n\u001b[1;32m    133\u001b[0m     _, indices \u001b[39m=\u001b[39m kmeans_plusplus(\n\u001b[1;32m    134\u001b[0m         X,\n\u001b[1;32m    135\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components,\n\u001b[1;32m    136\u001b[0m         random_state\u001b[39m=\u001b[39mrandom_state,\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m     resp[indices, np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components)] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 140\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(X, resp)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/mixture/_gaussian_mixture.py:778\u001b[0m, in \u001b[0;36mGaussianMixture._initialize\u001b[0;34m(self, X, resp)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecisions_init \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    777\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcovariances_ \u001b[39m=\u001b[39m covariances\n\u001b[0;32m--> 778\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecisions_cholesky_ \u001b[39m=\u001b[39m _compute_precision_cholesky(\n\u001b[1;32m    779\u001b[0m         covariances, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcovariance_type\n\u001b[1;32m    780\u001b[0m     )\n\u001b[1;32m    781\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecisions_cholesky_ \u001b[39m=\u001b[39m _compute_precision_cholesky_from_precisions(\n\u001b[1;32m    783\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecisions_init, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcovariance_type\n\u001b[1;32m    784\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/mixture/_gaussian_mixture.py:331\u001b[0m, in \u001b[0;36m_compute_precision_cholesky\u001b[0;34m(covariances, covariance_type)\u001b[0m\n\u001b[1;32m    329\u001b[0m             cov_chol \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39mcholesky(covariance, lower\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    330\u001b[0m         \u001b[39mexcept\u001b[39;00m linalg\u001b[39m.\u001b[39mLinAlgError:\n\u001b[0;32m--> 331\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(estimate_precision_error_message)\n\u001b[1;32m    332\u001b[0m         precisions_chol[k] \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39msolve_triangular(\n\u001b[1;32m    333\u001b[0m             cov_chol, np\u001b[39m.\u001b[39meye(n_features), lower\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    334\u001b[0m         )\u001b[39m.\u001b[39mT\n\u001b[1;32m    335\u001b[0m \u001b[39melif\u001b[39;00m covariance_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtied\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Fitting the mixture model failed because some components have ill-defined empirical covariance (for instance caused by singleton or collapsed samples). Try to decrease the number of components, or increase reg_covar."
     ]
    }
   ],
   "source": [
    "model = GaussianMixture(n_components=12, random_state=42, reg_covar=1e-5)\n",
    "\n",
    "y_pred = model.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
